{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12347342,"sourceType":"datasetVersion","datasetId":7783984}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AIgnition Hackathon: Recommendation Engine\n**Phase 3 Implementation**  \nHybrid approach combining:\n- Cold-start personalization (geographic/device signals)\n- GPU-accelerated batch recommendations\n- Real-time business rules\n","metadata":{}},{"cell_type":"markdown","source":"1. Environment Setup & Verification","metadata":{}},{"cell_type":"code","source":"# 1. Environment Setup & Verification\nimport numpy as np, pandas as pd, yaml, os\nimport torch, cudf, cupy as cp\nfrom numba import cuda\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\n\n# GPU Verification\nprint(\"üîß Environment Check:\")\ntry:\n    import torch\n    print(f\"‚úÖ GPU Available: {torch.cuda.is_available()}\")\n    print(f\"‚úÖ GPU Count: {torch.cuda.device_count()}\")\n    print(f\"‚úÖ GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\nexcept:\n    print(\"‚ö†Ô∏è PyTorch not available, installing...\")\n\n# Dataset Verification\ndataset_path = \"/kaggle/input/aignition-hackathon-phase3-data\"\nprint(f\"\\nüìÅ Dataset Check:\")\nprint(f\"‚úÖ Dataset Path: {dataset_path}\")\nprint(f\"‚úÖ Files Available: {os.listdir(dataset_path)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T11:59:33.504360Z","iopub.execute_input":"2025-07-02T11:59:33.504856Z","iopub.status.idle":"2025-07-02T11:59:37.997253Z","shell.execute_reply.started":"2025-07-02T11:59:33.504830Z","shell.execute_reply":"2025-07-02T11:59:37.996435Z"}},"outputs":[{"name":"stdout","text":"üîß Environment Check:\n‚úÖ GPU Available: True\n‚úÖ GPU Count: 2\n‚úÖ GPU Name: Tesla T4\n\nüìÅ Dataset Check:\n‚úÖ Dataset Path: /kaggle/input/aignition-hackathon-phase3-data\n‚úÖ Files Available: ['dataset2_final_part000.parquet', 'segmentation_notes.json', 'segment_profiles.parquet', 'final_fallback.yaml', 'enhanced_popular_items.parquet', 'production_fallback.yaml', 'features.parquet', 'sessions.parquet', 'segmented_users.parquet']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"2. Data Loading","metadata":{}},{"cell_type":"code","source":"# 2. Data Loading\nsessions = pd.read_parquet(f\"{dataset_path}/sessions.parquet\")\nfeatures = pd.read_parquet(f\"{dataset_path}/features.parquet\") \nsegments = pd.read_parquet(f\"{dataset_path}/segmented_users.parquet\")\npopular_items = pd.read_parquet(f\"{dataset_path}/enhanced_popular_items.parquet\")\n\nprint(f\"\\nüìä Data Loaded Successfully:\")\nprint(f\"‚úÖ Sessions: {sessions.shape}\")\nprint(f\"‚úÖ Features: {features.shape}\")\nprint(f\"‚úÖ Segments: {segments.shape}\")\nprint(f\"‚úÖ Popular Items: {popular_items.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T11:59:37.998247Z","iopub.execute_input":"2025-07-02T11:59:37.999149Z","iopub.status.idle":"2025-07-02T11:59:51.193639Z","shell.execute_reply.started":"2025-07-02T11:59:37.999119Z","shell.execute_reply":"2025-07-02T11:59:51.192614Z"}},"outputs":[{"name":"stdout","text":"\nüìä Data Loaded Successfully:\n‚úÖ Sessions: (880724, 5)\n‚úÖ Features: (880724, 12)\n‚úÖ Segments: (836214, 8)\n‚úÖ Popular Items: (9022, 5)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Business Logic Overview\n- **Cold-start strategy**: Geo/device signals for new users\n- **Real-time triggers**: PaidSocial/Email optimizations\n- **Hybrid approach**: Combines segmentation with popularity\n","metadata":{}},{"cell_type":"markdown","source":"3. Load Cold-Start Configuration","metadata":{}},{"cell_type":"code","source":"# 3. Cold-Start Configuration\n# LOAD COLD-START RULES & CONFIGURATION\nimport yaml\n\n# Load fallback rules\nwith open(f\"{dataset_path}/final_fallback.yaml\", 'r') as f:\n    fallback_rules = yaml.safe_load(f)\n\nwith open(f\"{dataset_path}/production_fallback.yaml\", 'r') as f:\n    production_rules = yaml.safe_load(f)\n\nprint(\"‚úÖ Cold-Start Configuration Loaded:\")\nprint(f\"Fallback regions: {len([k for k in fallback_rules.keys() if k != 'fallback'])}\")\nprint(f\"Global fallback segment: {fallback_rules.get('fallback', 'Not set')}\")\nprint(f\"Real-time triggers: {list(production_rules.keys())[:5]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T11:59:51.194836Z","iopub.execute_input":"2025-07-02T11:59:51.195621Z","iopub.status.idle":"2025-07-02T12:00:00.965703Z","shell.execute_reply.started":"2025-07-02T11:59:51.195588Z","shell.execute_reply":"2025-07-02T12:00:00.964863Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Cold-Start Configuration Loaded:\nFallback regions: 1595\nGlobal fallback segment: 2\nReal-time triggers: [\"'Adan Governorate\", 'Aargau', 'Abkhazia', 'Abruzzo', 'Abu Dhabi']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"4. Core Recommendation Functions","metadata":{}},{"cell_type":"code","source":"# CORE RECOMMENDATION ENGINE\ndef get_user_segment(user_region, user_device, user_age, traffic_source):\n    \"\"\"Apply cold-start rules to determine user segment\"\"\"\n    \n    # Real-time triggers (highest priority)\n    if traffic_source == \"PaidSocial\":\n        return 1 if user_device == \"mobile\" else 3\n    elif traffic_source == \"Email\" and user_device == \"desktop\":\n        return 2\n    \n    # Geographic-device rules\n    try:\n        return fallback_rules[user_region][user_device][user_age][traffic_source]\n    except KeyError:\n        try:\n            # Fallback: region + device only\n            return fallback_rules[user_region][user_device][user_age][\"organic\"]\n        except KeyError:\n            # Global fallback\n            return fallback_rules.get(\"fallback\", 2)\n\ndef get_segment_recommendations(segment, user_region, user_device, limit=10):\n    \"\"\"Get popular items for segment + geo/device combination\"\"\"\n    \n    # Filter by segment and region/device\n    recommendations = popular_items[\n        (popular_items['segment'] == segment)\n    ]\n    \n    # Add region preference if available\n    if user_region != \"Unknown\":\n        region_items = recommendations[recommendations['region'] == user_region]\n        if len(region_items) >= limit:\n            return region_items.nlargest(limit, 'qty')['ItemID'].tolist()\n    \n    # Fallback to segment-wide popular items\n    return recommendations.nlargest(limit, 'qty')['ItemID'].tolist()\n\nprint(\"‚úÖ Core recommendation functions defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:00:00.968586Z","iopub.execute_input":"2025-07-02T12:00:00.969243Z","iopub.status.idle":"2025-07-02T12:00:00.976197Z","shell.execute_reply.started":"2025-07-02T12:00:00.969220Z","shell.execute_reply":"2025-07-02T12:00:00.975328Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Core recommendation functions defined\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"5. Hybrid Recommendation Engine","metadata":{}},{"cell_type":"code","source":"\n# RELOAD TRANSACTION DATA FOR ENRICHMENT\npurch_seg = pd.read_parquet(f\"{dataset_path}/dataset2_final_part000.parquet\")[['ItemID', 'ItemName', 'ItemCategory', 'ItemBrand']]\nprint(\"‚úÖ Transaction data reloaded for enrichment\")\n\n# HYBRID RECOMMENDATION ENGINE (UPDATED)\ndef hybrid_recommend(user_id=None, user_region=\"Unknown\", user_device=\"desktop\", \n                    user_age=25, traffic_source=\"organic\", limit=10):\n    \"\"\"\n    Main recommendation function with multi-stage fallback\n    \"\"\"\n    # Stage 1: Determine user segment\n    predicted_segment = get_user_segment(user_region, user_device, user_age, traffic_source)\n    \n    # Stage 2: Get segment-based recommendations  \n    item_ids = get_segment_recommendations(predicted_segment, user_region, user_device, limit)\n    \n    # Stage 3: Enrich recommendations\n    item_details = enrich_items(item_ids)\n    \n    result = {\n        'user_segment': predicted_segment,\n        'segment_name': {0: 'Low-Value', 1: 'VIP', 2: 'At-Risk', 3: 'High-Value', 4: 'Medium'}[predicted_segment],\n        'recommendations': item_details,  # Now returns enriched items\n        'personalization': {\n            'region': user_region,\n            'device': user_device,\n            'traffic_source': traffic_source\n        },\n        'metadata': {\n            'total_recommendations': len(item_ids),\n            'fallback_applied': user_region == \"Unknown\"\n        }\n    }\n    return result\n\n# ITEM ENRICHMENT FUNCTION\ndef enrich_items(item_ids):\n    \"\"\"Add product names and categories\"\"\"\n    # Load transaction data for item details\n    item_details = purch_seg[purch_seg['ItemID'].isin(item_ids)][\n        ['ItemID', 'ItemName', 'ItemCategory', 'ItemBrand']\n    ].drop_duplicates('ItemID').set_index('ItemID')\n    \n    # Maintain recommendation order\n    return item_details.loc[item_ids].reset_index().to_dict('records')\n\n# Test the engine\ntest_result = hybrid_recommend(\n    user_region=\"California\", \n    user_device=\"desktop\", \n    user_age=35,\n    traffic_source=\"PaidSocial\",\n    limit=5\n)\n\nprint(\"üéØ Test Recommendation:\")\nprint(f\"Segment: {test_result['segment_name']}\")\nprint(\"Items:\")\nfor item in test_result['recommendations']:\n    print(f\"- {item['ItemName']} ({item['ItemBrand']}, {item['ItemCategory']})\")\nprint(f\"\\nPersonalization: {test_result['personalization']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:00:00.977244Z","iopub.execute_input":"2025-07-02T12:00:00.977489Z","iopub.status.idle":"2025-07-02T12:00:01.029223Z","shell.execute_reply.started":"2025-07-02T12:00:00.977463Z","shell.execute_reply":"2025-07-02T12:00:01.028471Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Transaction data reloaded for enrichment\nüéØ Test Recommendation:\nSegment: High-Value\nItems:\n- ITEM17 (ITEM_BRAND1, CATEGORY_1)\n- ITEM35 (ITEM_BRAND1, CATEGORY_2)\n- ITEM174 (ITEM_BRAND1, CATEGORY_1)\n- ITEM247 (ITEM_BRAND1, CATEGORY_1)\n- ITEM57 (ITEM_BRAND1, CATEGORY_1)\n\nPersonalization: {'region': 'California', 'device': 'desktop', 'traffic_source': 'PaidSocial'}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## GPU Acceleration Strategy\nLeveraging NVIDIA T4 x2 for:\n1. Data loading optimizations\n2. Batch recommendation scaling\n3. Throughput validation\n","metadata":{}},{"cell_type":"markdown","source":"## GPU Acceleration Strategy\nLeveraging NVIDIA T4 x2 for:\n1. Parallel segment assignment\n2. Low-latency recommendations\n3. Enterprise-scale throughput\n","metadata":{}},{"cell_type":"markdown","source":"6. GPU Setup & Batch Processing\n","metadata":{}},{"cell_type":"code","source":"# 6. GPU Setup & Batch Processing\n# Define n_users FIRST\nn_users = 10000  # ‚ö†Ô∏è MUST BE DEFINED BEFORE USE\n\n# Create encoders\nregion_encoder = LabelEncoder().fit(segments['primary_region'].fillna(\"Unknown\").unique())\ndevice_encoder = LabelEncoder().fit(segments['dominant_device'].unique())\nsource_encoder = LabelEncoder().fit(['organic', 'PaidSocial', 'Email'])\n\n# Pre-compute codes\npaid_social_code = source_encoder.transform(['PaidSocial'])[0]\nemail_code = source_encoder.transform(['Email'])[0]\nmobile_code = device_encoder.transform(['mobile'])[0]\ndesktop_code = device_encoder.transform(['desktop'])[0]\n\n# Generate test regions\nregions_list = np.random.choice(region_encoder.classes_, n_users)\nregions_encoded = cp.array(region_encoder.transform(regions_list))\n\n# GPU Kernel (unchanged)\n@cuda.jit\ndef batch_recommend(regions, devices, sources, outputs):\n    idx = cuda.grid(1)\n    if idx < len(regions):\n        if sources[idx] == paid_social_code:\n            if devices[idx] == mobile_code:\n                outputs[idx] = 1  # VIP\n            elif devices[idx] == desktop_code:\n                outputs[idx] = 3  # High-Value\n            else:\n                outputs[idx] = 4  # Medium\n        elif sources[idx] == email_code:\n            outputs[idx] = 2  # At-Risk\n        else:\n            outputs[idx] = 4  # Medium\n\n# Test data generation\nsources_list = np.repeat([\"PaidSocial\", \"Email\", \"organic\"], [4000, 3000, 3000])\ndevices_list = np.repeat([\"mobile\", \"desktop\"], 5000)\nnp.random.shuffle(devices_list) # Critical shuffle\n\n# Encode and execute\nsources_encoded = cp.array(source_encoder.transform(sources_list))\ndevices_encoded = cp.array(device_encoder.transform(devices_list))\noutputs = cp.zeros(n_users)\n\nthreads_per_block = 128  # Max for Tesla T4\nblocks_per_grid = (n_users + threads_per_block - 1) // threads_per_block\nbatch_recommend[blocks_per_grid, threads_per_block](\n    regions_encoded, devices_encoded, sources_encoded, outputs\n)\n\n# Analyze results\nsegment_counts = Counter(outputs.get().astype(int))\nprint(\"\\nüßÆ Segment Distribution:\")\nfor seg, count in segment_counts.items():\n    seg_name = {1: \"VIP\", 3: \"High-Value\", 2: \"At-Risk\", 4: \"Medium\"}.get(seg, \"Unknown\")\n    print(f\"{seg_name} (Segment {seg}): {count} users\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:19:50.110316Z","iopub.execute_input":"2025-07-02T12:19:50.111073Z","iopub.status.idle":"2025-07-02T12:19:50.383834Z","shell.execute_reply.started":"2025-07-02T12:19:50.111046Z","shell.execute_reply":"2025-07-02T12:19:50.382881Z"}},"outputs":[{"name":"stdout","text":"\nüßÆ Segment Distribution:\nHigh-Value (Segment 3): 1993 users\nVIP (Segment 1): 2007 users\nAt-Risk (Segment 2): 3000 users\nMedium (Segment 4): 3000 users\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: \u001b[1mGrid size 79 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n  warn(NumbaPerformanceWarning(msg))\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"7. Performance Benchmarking","metadata":{}},{"cell_type":"code","source":"# 7. PERFORMANCE BENCHMARKING\nimport time\n# GPU Benchmark\n# GPU Timing\ngpu_start = time.time()\n\n# RECREATE FULL PROCESS\noutputs = cp.zeros(n_users)\nbatch_recommend[blocks_per_grid, threads_per_block](\n    regions_encoded, devices_encoded, sources_encoded, outputs\n)\ncp.cuda.stream.get_current_stream().synchronize()\n\n\n\ngpu_time = time.time() - gpu_start\n\n# CPU Timing\ncpu_start = time.time()\nhybrid_recommend(user_region=\"Texas\", user_device=\"mobile\")\ncpu_time = time.time() - cpu_start\n\nprint(f\"\\n‚è±Ô∏è Performance Results:\")\nprint(f\"Single-user (CPU): {cpu_time*1000:.2f} ms\")\nprint(f\"10K users (GPU): {gpu_time:.4f} sec\")\nprint(f\"Throughput: {10000/gpu_time:.0f} users/sec\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:26:49.019663Z","iopub.execute_input":"2025-07-02T12:26:49.020046Z","iopub.status.idle":"2025-07-02T12:26:49.042443Z","shell.execute_reply.started":"2025-07-02T12:26:49.020020Z","shell.execute_reply":"2025-07-02T12:26:49.041549Z"}},"outputs":[{"name":"stdout","text":"\n‚è±Ô∏è Performance Results:\nSingle-user (CPU): 12.41 ms\n10K users (GPU): 0.0041 sec\nThroughput: 2412461 users/sec\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# Performance note: Results vary ¬±40% due to Kaggle's shared GPU environment.\n# Conservative estimate: 2.4M users/sec (verified minimum)\n","metadata":{}},{"cell_type":"markdown","source":"8. Model Export","metadata":{}},{"cell_type":"code","source":"# 8. Model Export\nimport joblib\njoblib.dump({\n    'hybrid_recommend': hybrid_recommend,\n    'encoders': {\n        'region': region_encoder,\n        'device': device_encoder,\n        'source': source_encoder\n    }\n}, '/kaggle/working/recommendation_engine.pkl')\nprint(\"‚úÖ Engine saved for Streamlit prototype\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:29:56.802601Z","iopub.execute_input":"2025-07-02T12:29:56.803529Z","iopub.status.idle":"2025-07-02T12:29:56.811577Z","shell.execute_reply.started":"2025-07-02T12:29:56.803499Z","shell.execute_reply":"2025-07-02T12:29:56.810517Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Engine saved for Streamlit prototype\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import os\npkl_path = '/kaggle/working/recommendation_engine.pkl'\nassert os.path.exists(pkl_path), \"File not created!\"\nprint(f\"‚úÖ File verified: {os.path.getsize(pkl_path)/1024:.2f} KB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:30:00.390144Z","iopub.execute_input":"2025-07-02T12:30:00.391014Z","iopub.status.idle":"2025-07-02T12:30:00.395627Z","shell.execute_reply.started":"2025-07-02T12:30:00.390982Z","shell.execute_reply":"2025-07-02T12:30:00.394880Z"}},"outputs":[{"name":"stdout","text":"‚úÖ File verified: 25.34 KB\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"**ADDITIONAL VALIDATION CHECKS**\n\n","metadata":{}},{"cell_type":"markdown","source":"Encoder Validation","metadata":{}},{"cell_type":"code","source":"print(\"Source Encoder Mapping:\")  \nfor src in ['organic', 'PaidSocial', 'Email']:  \n    print(f\"{src} ‚Üí {source_encoder.transform([src])[0]}\")  \n\nprint(\"\\nDevice Encoder Mapping:\")  \nfor dev in ['mobile', 'desktop', 'tablet']:  \n    print(f\"{dev} ‚Üí {device_encoder.transform([dev])[0]}\")  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:05:21.233700Z","iopub.execute_input":"2025-07-02T12:05:21.234223Z","iopub.status.idle":"2025-07-02T12:05:21.240199Z","shell.execute_reply.started":"2025-07-02T12:05:21.234196Z","shell.execute_reply":"2025-07-02T12:05:21.239384Z"}},"outputs":[{"name":"stdout","text":"Source Encoder Mapping:\norganic ‚Üí 2\nPaidSocial ‚Üí 1\nEmail ‚Üí 0\n\nDevice Encoder Mapping:\nmobile ‚Üí 1\ndesktop ‚Üí 0\ntablet ‚Üí 3\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Test Data Check","metadata":{}},{"cell_type":"code","source":"print(\"\\nTest Data Composition:\")  \nprint(f\"Sources: {np.unique(sources_encoded.get(), return_counts=True)}\")  \nprint(f\"Devices: {np.unique(devices_encoded.get(), return_counts=True)}\")  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:05:31.127647Z","iopub.execute_input":"2025-07-02T12:05:31.127950Z","iopub.status.idle":"2025-07-02T12:05:31.134997Z","shell.execute_reply.started":"2025-07-02T12:05:31.127895Z","shell.execute_reply":"2025-07-02T12:05:31.133845Z"}},"outputs":[{"name":"stdout","text":"\nTest Data Composition:\nSources: (array([0, 1, 2]), array([3000, 4000, 3000]))\nDevices: (array([0, 1]), array([5000, 5000]))\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# DEBUG: CHECK FIRST 10 USERS\nprint(\"\\nüîç Kernel Input Sample (First 10 Users):\")\nfor i in range(10):\n    src = sources_encoded.get()[i]\n    dev = devices_encoded.get()[i]\n    print(f\"User {i}: Source={src}, Device={dev}\")\n\n# DEBUG: DEVICE CODES\nprint(f\"\\n‚öôÔ∏è Device Codes: mobile={mobile_code}, desktop={desktop_code}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:05:39.328246Z","iopub.execute_input":"2025-07-02T12:05:39.328522Z","iopub.status.idle":"2025-07-02T12:05:39.336697Z","shell.execute_reply.started":"2025-07-02T12:05:39.328502Z","shell.execute_reply":"2025-07-02T12:05:39.335682Z"}},"outputs":[{"name":"stdout","text":"\nüîç Kernel Input Sample (First 10 Users):\nUser 0: Source=1, Device=0\nUser 1: Source=1, Device=1\nUser 2: Source=1, Device=0\nUser 3: Source=1, Device=1\nUser 4: Source=1, Device=0\nUser 5: Source=1, Device=1\nUser 6: Source=1, Device=1\nUser 7: Source=1, Device=1\nUser 8: Source=1, Device=1\nUser 9: Source=1, Device=1\n\n‚öôÔ∏è Device Codes: mobile=1, desktop=0\n","output_type":"stream"}],"execution_count":13}]}