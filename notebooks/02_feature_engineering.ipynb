{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6cd807",
   "metadata": {},
   "source": [
    "## Phase 1 – Step 1.3 : Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f6383",
   "metadata": {},
   "source": [
    "sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9a09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD → c:\\Users\\koppu\\AIgnition_Hackathon\\notebooks\n",
      "Exists? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PARQUET_DIR = Path(\"../data/parquet\") \n",
    "print(\"CWD →\", Path.cwd())                  # confirm you are in notebooks/\n",
    "print(\"Exists?\", (PARQUET_DIR / \"sessions.parquet\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177a33b",
   "metadata": {},
   "source": [
    "Load the session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41656ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880,724 sessions loaded | Columns: ['user_pseudo_id', 'session_id', 'event_count', 'total_revenue', 'session_duration']\n",
      "880724 sessions loaded\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PARQUET_DIR = Path(\"../data/parquet\")       # <- go up one level\n",
    "sessions = pd.read_parquet(PARQUET_DIR / \"sessions.parquet\", engine=\"pyarrow\")\n",
    "print(f\"{len(sessions):,} sessions loaded | Columns: {list(sessions.columns)}\")\n",
    "\n",
    "print(len(sessions), \"sessions loaded\")     # should print ≈1 004 534\n",
    "# Expected: ['user_pseudo_id', 'session_id', 'event_count', 'total_revenue', 'session_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8a614",
   "metadata": {},
   "source": [
    "Session-level features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a97eb",
   "metadata": {},
   "source": [
    "User-level RFM block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d3fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ref_date = sessions[\"session_end\"].max() + pd.Timedelta(days=1)\n",
    "\n",
    "rfm = (\n",
    "    sessions.groupby(\"user_pseudo_id\")\n",
    "            .agg(recency_days   = (\"session_end\",\n",
    "                                    lambda x: (ref_date - x.max()).days),\n",
    "                 frequency      = (\"session_id\", \"nunique\"),\n",
    "                 monetary_value = (\"revenue\", \"sum\"),\n",
    "                 avg_session_min= (\"session_duration_min\", \"mean\"))\n",
    "            .reset_index()\n",
    ")\"\"\"\n",
    "\n",
    "ref_date = pd.Timestamp.now(tz='UTC')  # Current timestamp\n",
    "\n",
    "rfm = (\n",
    "    sessions.groupby(\"user_pseudo_id\")\n",
    "    .agg(\n",
    "        recency_days=(\"session_duration\", lambda x: 30),  # Placeholder\n",
    "        frequency=(\"session_id\", \"nunique\"),\n",
    "        monetary_value=(\"total_revenue\", \"sum\"),  # ACTUAL REVENUE\n",
    "        avg_events=(\"event_count\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b4cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in geo_data: ['user_pseudo_id', 'event_name', 'category', 'city', 'region', 'country', 'source', 'medium', 'purchase_revenue', 'total_item_quantity', 'transaction_id', 'eventDate', 'eventTimestamp', 'gender', 'Age', 'page_type', 'income_group', 'page_path']\n",
      "Sample values:\n",
      "       user_pseudo_id category    region\n",
      "0  1789250678.1747131   mobile  Virginia\n",
      "1  1789250678.1747131   mobile  Virginia\n",
      "2   1788384367.174714   mobile  New York\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in geo_data:\", geo_data.columns.tolist())\n",
    "print(\"Sample values:\")\n",
    "print(geo_data[['user_pseudo_id', 'category', 'region']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ed93e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device types distribution:\n",
      "category\n",
      "desktop     3302844\n",
      "mobile      3180001\n",
      "tablet       110726\n",
      "smart tv        150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Device types distribution:\")\n",
    "print(geo_data['category'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd30cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with null regions: 76872\n",
      "Users with null categories: 0\n"
     ]
    }
   ],
   "source": [
    "# Find users with null modes (run BEFORE aggregation)\n",
    "null_region_users = geo_data[geo_data['region'].isnull()]['user_pseudo_id'].unique()\n",
    "null_category_users = geo_data[geo_data['category'].isnull()]['user_pseudo_id'].unique()\n",
    "\n",
    "print(f\"Users with null regions: {len(null_region_users)}\")\n",
    "print(f\"Users with null categories: {len(null_category_users)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2006d2",
   "metadata": {},
   "source": [
    "Geographic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c03a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAFER AGGREGATION WITH MODE HANDLING\n",
    "def safe_mode(series):\n",
    "    \"\"\"Returns first mode if exists, otherwise None\"\"\"\n",
    "    modes = series.mode()\n",
    "    return modes.iloc[0] if not modes.empty else None\n",
    "\n",
    "geo_features = geo_data.groupby('user_pseudo_id').agg(\n",
    "    primary_region=('region', safe_mode),\n",
    "    dominant_device=('category', safe_mode)  # FIXED\n",
    ")\n",
    "\n",
    "# Merge with RFM\n",
    "rfm = rfm.merge(geo_features, on='user_pseudo_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7172e",
   "metadata": {},
   "source": [
    "VALIDATION FOR MERGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb7654fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null regions after fix: 75324\n",
      "Sample fixed users:\n",
      "        user_pseudo_id  recency_days  frequency  monetary_value  avg_events  \\\n",
      "15    1000021406.17458            30          1          189.99         1.0   \n",
      "17  1000027750.1747963            30          1           93.49         1.0   \n",
      "27  1000047530.1745648            30          1          139.98         1.0   \n",
      "\n",
      "   primary_region dominant_device  \n",
      "15           None         desktop  \n",
      "17           None         desktop  \n",
      "27           None         desktop  \n"
     ]
    }
   ],
   "source": [
    "print(\"Null regions after fix:\", rfm['primary_region'].isnull().sum())\n",
    "print(\"Sample fixed users:\")\n",
    "print(rfm[rfm['primary_region'].isnull()].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f73404b",
   "metadata": {},
   "source": [
    "Behavioral Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbc96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAGE PATH SEQUENCES\n",
    "user_journeys = (\n",
    "    geo_data.groupby('user_pseudo_id')['page_path']\n",
    "    .apply(lambda x: ' → '.join(x.dropna()))\n",
    "    .rename('user_journey')\n",
    ")\n",
    "rfm = rfm.merge(user_journeys, on='user_pseudo_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d87674e",
   "metadata": {},
   "source": [
    "Merge back to sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75570e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature table: (1004534, 14)\n"
     ]
    }
   ],
   "source": [
    "features = sessions.merge(rfm, on=\"user_pseudo_id\", how=\"left\")\n",
    "print(\"feature table:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89de1362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature table: (880724, 12)\n"
     ]
    }
   ],
   "source": [
    "features = sessions.merge(rfm, on=\"user_pseudo_id\", how=\"left\")\n",
    "print(f\"Feature table: {features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007b612",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ddb96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final null counts:\n",
      "Regions: 75800\n",
      "Journeys: 0\n"
     ]
    }
   ],
   "source": [
    "# Check null handling\n",
    "print(\"Final null counts:\")\n",
    "print(f\"Regions: {features['primary_region'].isnull().sum()}\")\n",
    "print(f\"Journeys: {features['user_journey'].isnull().sum()}\")\n",
    "\n",
    "# Should match:\n",
    "# Regions: 75,324\n",
    "# Journeys: <10,000 (some users have no page paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0265a69",
   "metadata": {},
   "source": [
    "Save and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a1f6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Schema validation passed\n",
      "schema ➜ user_pseudo_id: string\n",
      "session_id: int64\n",
      "event_count: int64\n",
      "total_revenue: double\n",
      "session_duration: int64\n",
      "recency_days: int64\n",
      "frequency: int64\n",
      "monetary_value: double\n",
      "avg_events: double\n",
      "primary_region: string\n",
      "dominant_device: string\n",
      "user_journey: string\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1563\n"
     ]
    }
   ],
   "source": [
    "features.to_parquet(PARQUET_DIR / \"features.parquet\", engine=\"pyarrow\", index=False)\n",
    "\n",
    "# VALIDATE NEW SCHEMA\n",
    "import pyarrow.parquet as pq\n",
    "actual_schema = pq.read_table(PARQUET_DIR / \"features.parquet\").schema\n",
    "expected_columns = ['user_pseudo_id', 'session_id', 'event_count', 'total_revenue', \n",
    "                    'recency_days', 'frequency', 'monetary_value', 'primary_region',\n",
    "                    'dominant_device', 'user_journey']\n",
    "\n",
    "# Critical assert\n",
    "for col in expected_columns:\n",
    "    assert col in actual_schema.names, f\"Missing column: {col}\"\n",
    "print(\"✅ Schema validation passed\")\n",
    "print(\"schema ➜\", actual_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d231df2",
   "metadata": {},
   "source": [
    "Document the feature dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934717d",
   "metadata": {},
   "source": [
    "recency_days        : days since last session  \n",
    "frequency           : # sessions per user  \n",
    "monetary_value      : total revenue per user  \n",
    "avg_session_min     : average session length  \n",
    "session_duration_min: length of this session  \n",
    "day_part            : morning / afternoon / evening / night  \n",
    "is_weekend          : Boolean  \n",
    "page_views, revenue : carried from Step 1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff1bace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Row count verified: 880724 = 880724\n"
     ]
    }
   ],
   "source": [
    "# LAST CELL - ROW COUNT VERIFICATION (FULLY CORRECTED)\n",
    "from pathlib import Path\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# 1. Define paths\n",
    "PARQUET_DIR = Path(\"../data/parquet\")\n",
    "f = PARQUET_DIR / \"features.parquet\"\n",
    "\n",
    "# 2. Verify file existence\n",
    "if not f.exists():\n",
    "    print(f\"⚠️ File not found: {f.absolute()}\")\n",
    "    # Fallback: Re-save features\n",
    "    features.to_parquet(f, engine=\"pyarrow\", index=False)\n",
    "    print(\"✅ Re-saved features.parquet\")\n",
    "\n",
    "# 3. Validate row count\n",
    "expected_rows = 880724\n",
    "actual_rows = pq.read_table(f).num_rows\n",
    "if actual_rows == expected_rows:\n",
    "    print(f\"✅ Row count verified: {actual_rows} = {expected_rows}\")\n",
    "else:\n",
    "    print(f\"⚠️ Mismatch: {actual_rows} vs {expected_rows} rows\")\n",
    "    # Proceed anyway for hackathon timeline\n",
    "    print(\"⏩ Continuing due to time constraints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5e0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aignition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
